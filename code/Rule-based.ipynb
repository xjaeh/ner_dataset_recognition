{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and load sentences file\n",
    "import pandas as pd\n",
    "\n",
    "# Choose which file to predict\n",
    "df = pd.read_csv('Dataset_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regex and define the regex function\n",
    "import re\n",
    "Keywords = ['data\\s*(?:set|base)s?', 'corpus', 'corpora', 'tree\\s*bank', \n",
    "            '(?:train|test|validation|testing|trainings?)\\s*(?:set|data)',\n",
    "            'collections?', 'benchmarks?']\n",
    "\n",
    "expression = re.compile(r'\\b(' + '|'.join(Keywords) + r')\\b', flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load in the matcher\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK for the POS-tags\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise dataframe to put the predictions in \n",
    "dataset = pd.DataFrame(columns= ['Sentence #', 'Word', 'POS', 'Tag'])\n",
    "empty = []\n",
    "x=0\n",
    "\n",
    "# Loop through all sentences\n",
    "for _,row in df.iterrows():\n",
    "    sentence = row.text\n",
    "    number = row.id\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    match = re.findall(expression, sentence)\n",
    "    store = {}\n",
    "    store2 = {}\n",
    "    \n",
    "    \n",
    "    # When the sentence contains a keyword it gets put into the matcher\n",
    "    if len(match) > 0:\n",
    "        doc = nlp(sentence)\n",
    "        \n",
    "        # pattern one or two get the .... dataset for example\n",
    "        pattern = [{\"IS_PUNCT\": False, 'POS':{'IN': ['PROPN', 'NOUN', 'NUM']}, 'OP':'?'},{'LENGTH':{'>=': 2},'LOWER': {'NOT_IN': ['table', 'figure', 'results','data']},'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN', 'ADJ']}},\n",
    "                {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT', 'ADJ']}, 'OP':'*'},\n",
    "                {'TEXT': {'IN': ['and', 'or']}, 'OP':'?'},\n",
    "                {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT', 'ADJ']}, 'OP':'*'},\n",
    "                {\"TEXT\": {\"REGEX\": \"((:?d|D)ata\\s*(?:set|base)s?$|(:?C|c)orpus$|(:?C|c)orpora$|(:?T|t)ree\\s*bank$|(:?C|c)ollections?$|(:?B|b)enchmarks?)$|trainval$\"}}]\n",
    "        pattern2 = [{\"IS_PUNCT\": False, 'POS':{'IN': ['PROPN', 'NOUN', 'NUM']}, 'OP':'?'},{'LENGTH':{'>=': 2},'LOWER': {'NOT_IN': ['table', 'figure', 'results','data']},'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN', 'ADJ']}},\n",
    "                {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT', 'ADJ']}, 'OP':'*'},\n",
    "                {'TEXT': {'IN': ['and', 'or']}, 'OP':'?'},\n",
    "                {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT', 'ADJ']}, 'OP':'*'},\n",
    "                {\"TEXT\": {\"REGEX\": \"(train$|test$|validation$|testing$|trainings?$|data$)\"}},\n",
    "                {\"TEXT\": {\"REGEX\": \"(sets?|(:?D|d)atasets?|(:?D|d)atabases?)\"}}]\n",
    "        matcher.add('Dataset', None, pattern)\n",
    "        matcher.add('Dataset', None, pattern2)\n",
    "        matches = matcher(doc)\n",
    "        \n",
    "        # picks up things with a wider range \n",
    "        matcher = Matcher(nlp.vocab) \n",
    "        pattern3 = [{\"IS_PUNCT\": False, 'POS':{'IN': ['PROPN', 'NOUN', 'NUM']}, 'OP':'?'},{'LENGTH':{'>=': 2},'LOWER': {'NOT_IN': ['table', 'figure', 'results','data', 'dataset', 'database', 'references', 'discussion']},'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}},\n",
    "                   {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT']}, 'OP':'*'},\n",
    "                    {'TEXT': 'is'}, {'TEXT': 'a'}, {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT']}, 'OP':'*'},\n",
    "                    {\"TEXT\": {\"REGEX\": \"((:?d|D)ata\\s*(?:set|base)s?$|(:?C|c)orpus$|(:?C|c)orpora$|(:?T|t)ree\\s*bank$|(:?C|c)ollections?$|(:?B|b)enchmarks?)$|trainval$\"}}]\n",
    "        pattern4 = [{\"IS_PUNCT\": False, 'POS':{'IN': ['PROPN', 'NOUN', 'NUM']}, 'OP':'?'},{'LENGTH':{'>=': 2},'LOWER': {'NOT_IN': ['table', 'figure', 'results','data', 'dataset', 'database', 'references', 'discussion']},'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}},\n",
    "                   {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT']}, 'OP':'*'},\n",
    "                    {'TEXT': 'is'}, {'TEXT': 'a'}, {'LOWER':{'NOT_IN': [':', '.','datasets', 'data', 'databases']},'POS': {'IN': ['PROPN', 'NOUN', 'NUM', 'PUNCT']}, 'OP':'*'},\n",
    "                    {\"TEXT\": {\"REGEX\": \"(train$|test$|validation$|testing$|trainings?$|data$)\"}},\n",
    "                    {\"TEXT\": {\"REGEX\": \"(sets?|(:?D|d)atasets?|(:?D|d)atabases?)\"}}]\n",
    "        \n",
    "        # picks op the .... dataset\n",
    "        pattern5 = [{'LOWER':'the'},{'POS':{'IN': ['PROPN']}, 'LOWER': {'NOT_IN': ['training','test','testing']},'IS_LOWER' : True},\n",
    "                    {\"TEXT\": {\"REGEX\": \"((:?d|D)ata\\s*(?:set|base)s?$|(:?C|c)orpus$|(:?C|c)orpora$|(:?T|t)ree\\s*bank$|(:?C|c)ollections?$|(:?B|b)enchmarks?)$|trainval$\"}}]\n",
    "        pattern6 =  [{'LOWER':'the'},{'POS':{'IN': ['PROPN']}, 'LOWER': {'NOT_IN': ['training','test','testing']}, 'IS_LOWER' : True},\n",
    "                     {\"TEXT\": {\"REGEX\": \"(train$|test$|validation$|testing$|trainings?$|data$)\"}},\n",
    "                    {\"TEXT\": {\"REGEX\": \"(sets?|(:?D|d)atasets?|(:?D|d)atabases?)\"}}]\n",
    "        matcher.add('Dataset', None, pattern3)\n",
    "        matcher.add('Dataset', None, pattern4)\n",
    "        matcher.add('Dataset', None, pattern5)\n",
    "        matcher.add('Dataset', None, pattern6)\n",
    "        matches2 = matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            try: \n",
    "                store[end]\n",
    "            except:\n",
    "                store[end] = start\n",
    "            if store[end] > start:\n",
    "                store[end] = start\n",
    "        for match_id, start, end in matches2:\n",
    "            if str(doc[start]).lower() == 'the':\n",
    "                try: \n",
    "                    store[end]\n",
    "                except:\n",
    "                    store[end] = start + 1\n",
    "                if store[end] > start + 1:\n",
    "                    store[end] = start + 1\n",
    "            else:\n",
    "                test = str(doc[start:end])\n",
    "                test2 = re.split(' \\[\\d+] is a ', test)\n",
    "                test3 = test.split(' is a ')\n",
    "                if len(test2) == 2:\n",
    "                    end = start + len(test2[0].split(' '))\n",
    "                else:\n",
    "                    end = start + len(test3[0].split(' '))\n",
    "                try: \n",
    "                    store[end]\n",
    "                except:\n",
    "                    store[end] = start\n",
    "                if store[end] > start:\n",
    "                    store[end] = start\n",
    "        if ':' in str(doc[0:5]):\n",
    "            matcher = Matcher(nlp.vocab)\n",
    "            \n",
    "            # picks up sentences like Imagenet: ... \n",
    "            pattern8 = [{'LENGTH':{'>=': 2},'LOWER': {'NOT_IN': ['left','table', 'figure','results', 'discussion', 'datasets', 'database', 'dataset', 'databases', 'experiments', 'object', 'benchmark', 'experimental', 'problem', 'input', 'detection', 'data', 'classification', 'lite', 'training', 'tuning', 'experiment', 'top', 'next', 'trajectories', 'baselines', 'baseline', 'output', 'corpus','inputs', 'images', 'digits', 'ppos', 'topic', 'program']},'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}}, \n",
    "                        {'LOWER': {'NOT_IN':['.', ')', ':', 'table', 'figure','results', 'cover', 'alogirthm','histograms']},'IS_LOWER':False, 'POS':{'IN': ['PROPN', 'NOUN', 'NUM', 'ADJ']}, 'OP':'*'},{'TEXT': ':'}]\n",
    "            matcher.add('Dataset', None, pattern8)\n",
    "            doc2 = ' '.join([str(token) for token in doc[0:5]])\n",
    "            doc3 = nlp(doc2)\n",
    "            matches = matcher(doc3)\n",
    "            for match_id, start, end in matches:\n",
    "                try: \n",
    "                    store[end-1]\n",
    "                except:\n",
    "                    store[end-1] = start \n",
    "                if store[end-1] > start :\n",
    "                    store[end-1] = start\n",
    "                \n",
    "        # deletes picks with a in front of it        \n",
    "        for key in list(store):\n",
    "            start = store[key]\n",
    "            if str(doc[start-1]).lower() in ['a', 'an']:\n",
    "                del store[key]\n",
    "                continue\n",
    "            elif str(doc[start-2]).lower() in ['a', 'an']:\n",
    "                del store[key]\n",
    "                continue\n",
    "            elif str(doc[start-3]).lower() in ['a', 'an']:\n",
    "                del store[key]\n",
    "                continue\n",
    "        for key in store.keys():\n",
    "            try:\n",
    "                store2[store[key]]\n",
    "            except:\n",
    "                store2[store[key]] = key\n",
    "            if store2[store[key]] < key:\n",
    "                store2[store[key]] = key\n",
    "            \n",
    "        if len(store) == 0:\n",
    "            matcher = Matcher(nlp.vocab)\n",
    "            \n",
    "            # picks up examples like on MNIST\n",
    "            pattern7 = [{'TEXT':'on'},{'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'LENGTH':{'>=': 2}}, \n",
    "                        {'TEXT': {'NOT_IN':['.', ')']},'IS_LOWER':False, 'OP':'*'}]\n",
    "            matcher.add('Dataset', None, pattern7)\n",
    "            matches = matcher(doc) \n",
    "            for match_id, start, end in matches:\n",
    "                try: \n",
    "                    store[end]\n",
    "                except:\n",
    "                    store[end] = start + 1\n",
    "                if store[end] > start + 1:\n",
    "                    store[end] = start + 1\n",
    "            for key in store.keys():\n",
    "                try:\n",
    "                    store2[store[key]]\n",
    "                except:\n",
    "                    store2[store[key]] = key\n",
    "                if store2[store[key]] < key:\n",
    "                    store2[store[key]] = key\n",
    "                \n",
    "                \n",
    "        if len(store) == 0:\n",
    "            matcher = Matcher(nlp.vocab)\n",
    "            if 'datasets' in sentence or 'databases' in sentence or 'collections' in sentence or 'corpora' in sentence or 'benchmarks' in sentence or 'Datasets' in sentence or 'Databases' in sentence or 'Collections' in sentence or 'Corpora' in sentence or 'Benchmarks' in sentence:\n",
    "                matcher = Matcher(nlp.vocab)\n",
    "                \n",
    "                # picks op things like the following datasets: MNIST, SVHN & Imagenet\n",
    "                pattern9 = [{'LOWER': {'IN': ['datasets', 'collections', 'corpora', 'databases', 'benchmarks', '|']}},{'TEXT':{'IN':[',',':']}, 'OP':'?'},{'TEXT':'like', 'OP':'?'}, \n",
    "                           {'LENGTH':{'>=': 2},'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':'and', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'},{'IS_LOWER':False, 'OP':'?'}]\n",
    "                pattern10 = [{'LOWER': {'IN': ['datasets', 'collections', 'corpora', 'databases', 'benchmarks', '|']}},{'TEXT':'for'},{'OP':'*'},{'TEXT':{'IN':[',',':']}, 'OP':'?'}, \n",
    "                           {'LENGTH':{'>=': 2},'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':',', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'}, {'TEXT':'and', 'OP':'?'},\n",
    "                          {'IS_LOWER': False, \"IS_PUNCT\": False, 'IS_DIGIT':False, 'POS':{'IN': ['PROPN', 'NOUN']}, 'OP':'*'}, \n",
    "                           {'IS_LOWER': False, 'OP':'*'},{'IS_LOWER':False, 'OP':'?'}]\n",
    "                matcher.add('Dataset', None, pattern9)\n",
    "                matcher.add('Dataset', None, pattern10)\n",
    "                matches = matcher(doc)\n",
    "                for match_id, start, end in matches:\n",
    "                    try: \n",
    "                        store[end]\n",
    "                    except:\n",
    "                        store[end] = start\n",
    "                    if store[end] > start:\n",
    "                        store[end] = start\n",
    "                for key in store.keys():\n",
    "                    try:\n",
    "                        store2[store[key]]\n",
    "                    except:\n",
    "                        store2[store[key]] = key\n",
    "                    if store2[store[key]] < key:\n",
    "                        store2[store[key]] = key\n",
    "                \n",
    "                multiples = []\n",
    "                for key in store2.keys():\n",
    "                    multiples.append([key,store2[key]])\n",
    "                for multiple in multiples:\n",
    "                    store = {}\n",
    "                    store2 = {}\n",
    "                    matcher = Matcher(nlp.vocab)\n",
    "                    \n",
    "                    # Removes the keywords at the matches before\n",
    "                    pattern11 = [{'LENGTH':{'>=': 2},'LOWER': {'NOT_IN': ['datasets', 'collections', 'corpora', 'databases', 'benchmarks']},'IS_LOWER': False, \"IS_PUNCT\": False, \n",
    "                                  'POS':{'IN': ['PROPN', 'NOUN']}}, \n",
    "                           {'TEXT': {'NOT_IN': [',','.','[', ']']},'IS_LOWER': False, 'OP':'*'}]\n",
    "                    matcher.add('Dataset', None, pattern11)\n",
    "                    doc2 = ' '.join([str(token) for token in doc[multiple[0]:multiple[1]]])\n",
    "                    doc3 = nlp(doc2)\n",
    "                    matches2 = matcher(doc3)\n",
    "                    for match_id, start, end in matches2:\n",
    "                        try: \n",
    "                            store[end + multiple[0]]\n",
    "                        except:\n",
    "                            store[end + multiple[0]] = start + multiple[0]\n",
    "                        if store[end + multiple[0]] > start + multiple[0]:\n",
    "                            store[end + multiple[0]] = start + multiple[0]\n",
    "                    for key in store.keys():\n",
    "                        try:\n",
    "                            store2[store[key]]\n",
    "                        except:\n",
    "                            store2[store[key]] = key\n",
    "                        if store2[store[key]] < key:\n",
    "                            store2[store[key]] = key\n",
    "    sent = nlp(sentence)\n",
    "    sent = [str(token) for token in sent]\n",
    "    tags = nltk.pos_tag(sent)\n",
    "    end = 0\n",
    "    for i in range(len(sent)):\n",
    "        if any([t.isalpha() for t in str(sent[i])]) or any([t.isdigit for t in str(sent[i])]) or any([t.ispunct for t in str(sent[i])]):\n",
    "            if len(store2) == 0:\n",
    "                dataset = dataset.append({'Sentence #':'Sentence: ' + str(number), 'Word':tags[i][0], 'POS': tags[i][1], 'Tag': 'O'}, ignore_index=True)\n",
    "            elif i not in store2.keys() and i >= end:\n",
    "                dataset = dataset.append({'Sentence #':'Sentence: ' + str(number), 'Word':tags[i][0], 'POS': tags[i][1], 'Tag': 'O'}, ignore_index=True)\n",
    "            elif i in store2.keys():\n",
    "                dataset = dataset.append({'Sentence #':'Sentence: ' + str(number), 'Word':tags[i][0], 'POS': tags[i][1], 'Tag': 'B'}, ignore_index=True)\n",
    "                end = store2[i]\n",
    "            else:\n",
    "                dataset = dataset.append({'Sentence #':'Sentence: ' + str(number), 'Word':tags[i][0], 'POS': tags[i][1], 'Tag': 'I'}, ignore_index=True)\n",
    "\n",
    "# Delete # to see how far the rule-based system is \n",
    "#     print(x)\n",
    "    x+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset, changee name to give the file an other name\n",
    "dataset.to_csv('RULEBASED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
